{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4052191f",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34dd0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be63f49",
   "metadata": {},
   "source": [
    "## Required files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c28ca",
   "metadata": {},
   "source": [
    "There are 5 required data files before preprocessing. Please download both DepMap files manually from the hyperlinks. The cell below will download everything else.\n",
    "\n",
    "(1) CTRPv2 response data\n",
    "\n",
    "(2) GDSC response data \n",
    "\n",
    "(3) gCSI response data \n",
    "\n",
    "(4) [DepMap cell line gene expression](https://depmap.org/portal/data_page/?tab=allData&releasename=DepMap%20Public%2024Q4&filename=OmicsExpressionProteinCodingGenesTPMLogp1.csv)\n",
    "\n",
    "(5) [DepMap manifest](https://depmap.org/portal/data_page/?tab=allData&releasename=DepMap%20Public%2024Q4&filename=Model.csv) \n",
    "\n",
    "(6) TCGA gene expression - Obtained individually from [UCSC Xena Browser](https://xenabrowser.net/datapages/?cohort=GDC%20TCGA%20Acute%20Myeloid%20Leukemia%20(LAML)&removeHub=https%3A%2F%2Fxena.treehouse.gi.ucsc.edu%3A443) (GDC hub, STAR TPM). Link provided is Google Drive maintained with all patient expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b015cdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-28 17:11:15--  https://ctd2-data.nci.nih.gov/Public/Broad/CTRPv2.0_2015_ctd2_ExpandedDataset/CTRPv2.0_2015_ctd2_ExpandedDataset.zip\n",
      "Resolving ctd2-data.nci.nih.gov (ctd2-data.nci.nih.gov)... 129.43.254.216, 2607:f220:41d:21c1::812b:fed8\n",
      "Connecting to ctd2-data.nci.nih.gov (ctd2-data.nci.nih.gov)|129.43.254.216|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 342737645 (327M) [application/zip]\n",
      "Saving to: ‘CTRPv2.0_2015_ctd2_ExpandedDataset.zip’\n",
      "\n",
      "CTRPv2.0_2015_ctd2_ 100%[===================>] 326.86M  2.75MB/s    in 2m 0s   \n",
      "\n",
      "2025-05-28 17:13:15 (2.72 MB/s) - ‘CTRPv2.0_2015_ctd2_ExpandedDataset.zip’ saved [342737645/342737645]\n",
      "\n",
      "Archive:  CTRPv2.0_2015_ctd2_ExpandedDataset.zip\n",
      "  inflating: CTRPv2.0._COLUMNS.xlsx  \n",
      "  inflating: CTRPv2.0._INFORMER_SET.xlsx  \n",
      "  inflating: CTRPv2.0._README.docx   \n",
      "  inflating: MANIFEST.txt            \n",
      "  inflating: v20._COLUMNS.txt        \n",
      "  inflating: v20.data.curves_post_qc.txt  \n",
      "  inflating: v20.data.per_cpd_avg.txt  \n",
      "  inflating: v20.data.per_cpd_post_qc.txt  \n",
      "  inflating: v20.data.per_cpd_pre_qc.txt  \n",
      "  inflating: v20.data.per_cpd_well.txt  \n",
      "  inflating: v20.meta.media_comp.txt  \n",
      "  inflating: v20.meta.per_assay_plate.txt  \n",
      "  inflating: v20.meta.per_cell_line.txt  \n",
      "  inflating: v20.meta.per_compound.txt  \n",
      "  inflating: v20.meta.per_experiment.txt  \n",
      "  inflating: v20._README.txt         \n",
      "--2025-05-28 17:13:27--  https://cog.sanger.ac.uk/cancerrxgene/GDSC_release8.5/GDSC2_fitted_dose_response_27Oct23.xlsx\n",
      "Resolving cog.sanger.ac.uk (cog.sanger.ac.uk)... 193.62.203.62, 193.62.203.63, 193.62.203.61\n",
      "Connecting to cog.sanger.ac.uk (cog.sanger.ac.uk)|193.62.203.62|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 21330376 (20M) [application/vnd.openxmlformats-officedocument.spreadsheetml.sheet]\n",
      "Saving to: ‘GDSC2_fitted_dose_response_27Oct23.xlsx’\n",
      "\n",
      "GDSC2_fitted_dose_r 100%[===================>]  20.34M  5.29MB/s    in 5.1s    \n",
      "\n",
      "2025-05-28 17:13:33 (3.98 MB/s) - ‘GDSC2_fitted_dose_response_27Oct23.xlsx’ saved [21330376/21330376]\n",
      "\n",
      "--2025-05-28 17:13:33--  http://research-pub.gene.com/gCSI_GRvalues2019/gCSI_GRdata_v1.3.tsv.tar.gz\n",
      "Resolving research-pub.gene.com (research-pub.gene.com)... 72.34.128.38\n",
      "Connecting to research-pub.gene.com (research-pub.gene.com)|72.34.128.38|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6476758 (6.2M) [application/octet-stream]\n",
      "Saving to: ‘gCSI_GRdata_v1.3.tsv.tar.gz’\n",
      "\n",
      "gCSI_GRdata_v1.3.ts 100%[===================>]   6.18M  1.11MB/s    in 5.8s    \n",
      "\n",
      "2025-05-28 17:13:39 (1.06 MB/s) - ‘gCSI_GRdata_v1.3.tsv.tar.gz’ saved [6476758/6476758]\n",
      "\n",
      "OUTPUT/gCSI_GRvalues_v1.3.tsv\n",
      "OUTPUT/gCSI_GRmetrics_v1.3.tsv\n",
      "/research/labs/microbiome/chia/m214779/miniconda3/envs/drp/lib/python3.11/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1wdGLJVAVCtK7Az4qtjsTvw-RJ-PLiIue\n",
      "From (redirected): https://drive.google.com/uc?id=1wdGLJVAVCtK7Az4qtjsTvw-RJ-PLiIue&confirm=t&uuid=0b552dde-860e-4bdb-ad88-0726b4c0702b\n",
      "To: /research/labs/microbiome/chia/m214779/drug_blind_generalization/tcga_expression_data.zip\n",
      "100%|██████████████████████████████████████| 3.15G/3.15G [02:20<00:00, 22.4MB/s]\n",
      "unzip:  cannot find or open tcga_patient_expression.zip, tcga_patient_expression.zip.zip or tcga_patient_expression.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget https://ctd2-data.nci.nih.gov/Public/Broad/CTRPv2.0_2015_ctd2_ExpandedDataset/CTRPv2.0_2015_ctd2_ExpandedDataset.zip #CTRPv2\n",
    "!unzip CTRPv2.0_2015_ctd2_ExpandedDataset.zip\n",
    "!wget https://cog.sanger.ac.uk/cancerrxgene/GDSC_release8.5/GDSC2_fitted_dose_response_27Oct23.xlsx #GDSC2\n",
    "!wget http://research-pub.gene.com/gCSI_GRvalues2019/gCSI_GRdata_v1.3.tsv.tar.gz #gCSI\n",
    "!tar -xzvf gCSI_GRdata_v1.3.tsv.tar.gz\n",
    "!gdown --id 1wdGLJVAVCtK7Az4qtjsTvw-RJ-PLiIue #TCGA patient expression, please contact authors if this fails. Alternatively, download files manually from XENA browser above.\n",
    "!unzip tcga_expression_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa7d78",
   "metadata": {},
   "source": [
    "## Generate response files for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0732fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('input_files'):\n",
    "    os.mkdir('input_files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd2498",
   "metadata": {},
   "source": [
    "We generate response files where each line is a tab-separated list containing (cell line, drug, response)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c99a06",
   "metadata": {},
   "source": [
    "### CTRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f78bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('input_files/ctrp'):\n",
    "    os.mkdir('input_files/ctrp')\n",
    "cellLine_meta_df = pd.read_csv('v20.meta.per_cell_line.txt', sep='\\t')\n",
    "experiment_meta_df = pd.read_csv('v20.meta.per_experiment.txt', sep='\\t')\n",
    "drug_meta_df = pd.read_csv('v20.meta.per_compound.txt', sep='\\t')\n",
    "experiment_results = pd.read_csv('v20.data.curves_post_qc.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39f43dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map ID values to drugs and cell lines, this is how they are represented in experiments.\n",
    "id2cell = dict(zip(cellLine_meta_df.master_ccl_id, cellLine_meta_df.ccl_name))\n",
    "id2drug = dict(zip(drug_meta_df.master_cpd_id, drug_meta_df.cpd_name))\n",
    "\n",
    "# Get dict where key = experiment ID, val = cell line ID\n",
    "exp2cell = dict(zip(experiment_meta_df.experiment_id, experiment_meta_df.master_ccl_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b764572",
   "metadata": {},
   "source": [
    "#### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a14715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict that is the final precursor for our tuple output file\n",
    "auc_dict = dict(zip(zip(experiment_results.experiment_id, experiment_results.master_cpd_id), experiment_results.area_under_curve))\n",
    "auc_named_dict = {}\n",
    "for k,v in auc_dict.items():\n",
    "    auc_named_dict[(id2cell[exp2cell[k[0]]], id2drug[k[1]])] = v\n",
    "\n",
    "# Prevent from appending to file if it's already there\n",
    "if os.path.exists('input_files/ctrp/ctrp_auc.txt'):\n",
    "    os.remove('input_files/ctrp/ctrp_auc.txt')\n",
    "\n",
    "with open('input_files/ctrp/ctrp_auc.txt', 'a') as f:\n",
    "    for k,v in auc_named_dict.items():\n",
    "        f.write(f'{k[0]}\\t{k[1]}\\t{v}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa841e",
   "metadata": {},
   "source": [
    "#### EC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f622b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec50_dict = dict(zip(zip(experiment_results.experiment_id, experiment_results.master_cpd_id), experiment_results.apparent_ec50_umol))\n",
    "ec50_named_dict = {}\n",
    "for k,v in ec50_dict.items():\n",
    "    if v >= -20 and v <= 20: # CTRP reports values in apparent ec50 uM, some of these values are extreme and disrupt training (exploding loss). Filter for realistic values. (20 + -6 = 10^14 M concentration...)\n",
    "        ec50_named_dict[(id2cell[exp2cell[k[0]]], id2drug[k[1]])] = v\n",
    "\n",
    "# Prevent from appending to file if it's already there\n",
    "if os.path.exists('input_files/ctrp/ctrp_ec50.txt'):\n",
    "    os.remove('input_files/ctrp/ctrp_ec50.txt')\n",
    "\n",
    "with open('input_files/ctrp/ctrp_ec50.txt', 'a') as f:\n",
    "    for k,v in ec50_named_dict.items():\n",
    "        f.write(f'{k[0]}\\t{k[1]}\\t{v}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a46024",
   "metadata": {},
   "source": [
    "### GDSC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c51df",
   "metadata": {},
   "source": [
    "GDSC is much easier, it's all in one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf01dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('input_files/gdsc'):\n",
    "    os.mkdir('input_files/gdsc')\n",
    "gdsc_response_df = pd.read_excel('GDSC2_fitted_dose_response_27Oct23.xlsx')\n",
    "gdsc_response_df[['CELL_LINE_NAME', 'DRUG_NAME', 'LN_IC50']].to_csv('input_files/gdsc/gdsc_ec50.txt', sep='\\t', header=False, index=False)\n",
    "gdsc_response_df[['CELL_LINE_NAME', 'DRUG_NAME', 'AUC']].to_csv('input_files/gdsc/gdsc_auc.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563fcb8b",
   "metadata": {},
   "source": [
    "### gCSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecc65c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "gCSI_df = pd.read_csv('/research/labs/microbiome/chia/m214779/gCSI/gCSI_GRmetrics_v1.3.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bba5fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('input_files/gcsi'):\n",
    "    os.mkdir('input_files/gcsi')\n",
    "\n",
    "# gCSI data has missing values, have to filter for them for each metric as we go\n",
    "\n",
    "temp = gCSI_df[gCSI_df['GR50'].notna()]\n",
    "temp = temp[temp['GR50'] < np.inf]\n",
    "temp = temp[temp['GR50'] > -np.inf]\n",
    "temp['GR50'] = temp['GR50'].apply(np.log) # log transform GR50 for prediction\n",
    "temp[['Norm_CellLineName', 'Norm_DrugName', 'GR50']].to_csv('input_files/gcsi/gcsi_gr50.txt', sep='\\t', header=False, index=False)\n",
    "\n",
    "temp = gCSI_df[gCSI_df['GR_AOC'].notna()]\n",
    "temp = temp[temp['GR_AOC'] < np.inf]\n",
    "temp = temp[temp['GR_AOC'] > -np.inf]\n",
    "temp[['Norm_CellLineName', 'Norm_DrugName', 'GR_AOC']].to_csv('input_files/gcsi/gcsi_aoc.txt', sep='\\t', header=False, index=False)\n",
    "\n",
    "temp = gCSI_df[gCSI_df['GRmax'].notna()]\n",
    "temp = temp[temp['GRmax'] < np.inf]\n",
    "temp = temp[temp['GRmax'] > -np.inf]\n",
    "temp[['Norm_CellLineName', 'Norm_DrugName', 'GRmax']].to_csv('input_files/gcsi/gcsi_grmax.txt', sep='\\t', header=False, index=False)\n",
    "\n",
    "temp = gCSI_df[gCSI_df['Emax'].notna()]\n",
    "temp = temp[temp['Emax'] < np.inf]\n",
    "temp = temp[temp['Emax'] > -np.inf]\n",
    "temp[['Norm_CellLineName', 'Norm_DrugName', 'Emax']].to_csv('input_files/gcsi/gcsi_emax.txt', sep='\\t', header=False, index=False)\n",
    "\n",
    "temp = gCSI_df[gCSI_df['GRinf'].notna()]\n",
    "temp = temp[temp['GRinf'] < np.inf]\n",
    "temp = temp[temp['GRinf'] > -np.inf]\n",
    "temp[['Norm_CellLineName', 'Norm_DrugName', 'GRinf']].to_csv('input_files/gcsi/gcsi_grinf.txt', sep='\\t', header=False, index=False)\n",
    "\n",
    "temp = gCSI_df[gCSI_df['GR_05uM_fit'].notna()]\n",
    "temp = temp[temp['GR_05uM_fit'] < np.inf]\n",
    "temp = temp[temp['GR_05uM_fit'] > -np.inf]\n",
    "temp[['Norm_CellLineName', 'Norm_DrugName', 'GR_05uM_fit']].to_csv('input_files/gcsi/gcsi_gr_05um_fit.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b2b03",
   "metadata": {},
   "source": [
    "## Filtering datasets for cell lines with expression values in DepMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b633b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_files/gdsc/gdsc_ec50.txt\n",
      "(242036, 3)\n",
      "(234020, 3)\n",
      "input_files/gdsc/gdsc_auc.txt\n",
      "(242036, 3)\n",
      "(234020, 3)\n",
      "input_files/gcsi/gcsi_grmax.txt\n",
      "(16304, 3)\n",
      "(15835, 3)\n",
      "input_files/gcsi/gcsi_gr50.txt\n",
      "(10765, 3)\n",
      "(10446, 3)\n",
      "input_files/gcsi/gcsi_grinf.txt\n",
      "(16304, 3)\n",
      "(15835, 3)\n",
      "input_files/gcsi/gcsi_gr_05um_fit.txt\n",
      "(16304, 3)\n",
      "(15835, 3)\n",
      "input_files/gcsi/gcsi_emax.txt\n",
      "(16688, 3)\n",
      "(16203, 3)\n",
      "input_files/gcsi/gcsi_aoc.txt\n",
      "(16304, 3)\n",
      "(15835, 3)\n",
      "input_files/ctrp/ctrp_auc.txt\n",
      "(387130, 3)\n",
      "(365321, 3)\n",
      "input_files/ctrp/ctrp_ec50.txt\n",
      "(282825, 3)\n",
      "(266709, 3)\n"
     ]
    }
   ],
   "source": [
    "index_df = pd.read_csv('Model.csv')\n",
    "strip_dict = pd.Series(index_df['ModelID'].values,index=index_df['StrippedCellLineName']).to_dict()\n",
    "\n",
    "# Get all of our input response files\n",
    "response_files = []\n",
    "for dirpath, dirnames, filenames in os.walk('input_files'):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(dirpath, filename)\n",
    "        response_files.append(file_path)\n",
    "\n",
    "for response_file in response_files:\n",
    "    print(response_file)\n",
    "    curr_df = pd.read_csv(response_file, sep='\\t', header=None, index_col=None)\n",
    "    print(curr_df.shape)\n",
    "    curr_df.iloc[:,0] = curr_df.iloc[:,0].str.replace('-', '')\n",
    "    curr_df.iloc[:,0] = curr_df.iloc[:,0].str.upper()\n",
    "    curr_df.iloc[:,0] = curr_df.iloc[:,0].map(strip_dict)\n",
    "    curr_df = curr_df[curr_df.iloc[:,0].notna()]\n",
    "    print(curr_df.shape) # print change in df shape for each input file\n",
    "    root, dataset, metric = response_file.replace('.txt', '').split('/')\n",
    "    curr_df.to_csv(f'{root}/{dataset}/{metric}'+ '_expfilt.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8dcc8f",
   "metadata": {},
   "source": [
    "## Filter datasets by morgan fingerprint files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c8deaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/research/labs/microbiome/chia/m214779/miniconda3/envs/drp/lib/python3.11/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1XBMuz3YeHSRh1mtFdy3Rb-4mqMoF7FMQ\n",
      "To: /research/labs/microbiome/chia/m214779/drug_blind_generalization/fingerprints.zip\n",
      "100%|█████████████████████████████████████████| 108k/108k [00:00<00:00, 180MB/s]\n",
      "Archive:  fingerprints.zip\n",
      "  inflating: fingerprints/ctrp_fingerprints.txt  \n",
      "  inflating: fingerprints/gcsi_fingerprints.txt  \n",
      "  inflating: fingerprints/gdsc_fingerprints.txt  \n"
     ]
    }
   ],
   "source": [
    "# Download fingerprint files\n",
    "!gdown --id 1XBMuz3YeHSRh1mtFdy3Rb-4mqMoF7FMQ\n",
    "!unzip fingerprints.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f133d5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_files/gdsc/gdsc_ec50_expfilt.txt\n",
      "(234020, 3)\n",
      "(194491, 3)\n",
      "input_files/gdsc/gdsc_auc_expfilt.txt\n",
      "(234020, 3)\n",
      "(194491, 3)\n",
      "input_files/gcsi/gcsi_emax_expfilt.txt\n",
      "(16203, 3)\n",
      "(11470, 3)\n",
      "input_files/gcsi/gcsi_gr_05um_fit_expfilt.txt\n",
      "(15835, 3)\n",
      "(11198, 3)\n",
      "input_files/gcsi/gcsi_grmax_expfilt.txt\n",
      "(15835, 3)\n",
      "(11198, 3)\n",
      "input_files/gcsi/gcsi_grinf_expfilt.txt\n",
      "(15835, 3)\n",
      "(11198, 3)\n",
      "input_files/gcsi/gcsi_aoc_expfilt.txt\n",
      "(15835, 3)\n",
      "(11198, 3)\n",
      "input_files/gcsi/gcsi_gr50_expfilt.txt\n",
      "(10446, 3)\n",
      "(7635, 3)\n",
      "input_files/ctrp/ctrp_auc_expfilt.txt\n",
      "(365321, 3)\n",
      "(365321, 3)\n",
      "input_files/ctrp/ctrp_ec50_expfilt.txt\n",
      "(266709, 3)\n",
      "(266709, 3)\n"
     ]
    }
   ],
   "source": [
    "response_files = []\n",
    "for dirpath, dirnames, filenames in os.walk('input_files'):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('expfilt.txt'):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            response_files.append(file_path)\n",
    "\n",
    "for response_file in response_files:\n",
    "    print(response_file)\n",
    "    root, dataset, metric = response_file.replace('_expfilt.txt', '').split('/')\n",
    "    response_df = pd.read_csv(response_file, sep='\\t', header=None, index_col=None)\n",
    "    print(response_df.shape)\n",
    "    fp_df = pd.read_csv(f'fingerprints/{dataset}_fingerprints.txt', sep='\\t', index_col=0)\n",
    "    filt_drugs = list(fp_df.index)\n",
    "    response_df = response_df[response_df.iloc[:,1].isin(filt_drugs)]\n",
    "    print(response_df.shape)\n",
    "    response_df.to_csv(f'{root}/{dataset}/{metric}'+ '_expfilt_fpfilt.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c858f6",
   "metadata": {},
   "source": [
    "## Filter expression data to match with TCGA expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8709b1bc",
   "metadata": {},
   "source": [
    "Original planned utility of model was with patient few-shot example, so expression has been filtered to match up with TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d28c634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60660, 424)\n",
      "(60660, 1013)\n",
      "(60660, 1567)\n",
      "(60660, 1754)\n",
      "(60660, 2227)\n",
      "(60660, 2306)\n",
      "(60660, 2354)\n",
      "(60660, 2505)\n",
      "(60660, 3039)\n",
      "(60660, 3467)\n",
      "(60660, 3981)\n",
      "(60660, 4179)\n",
      "(60660, 4354)\n",
      "(60660, 4783)\n",
      "(60660, 5393)\n",
      "(60660, 5450)\n",
      "(60660, 6016)\n",
      "(60660, 6172)\n",
      "(60660, 6757)\n",
      "(60660, 7080)\n",
      "(60660, 7202)\n",
      "(60660, 7774)\n",
      "(60660, 7865)\n",
      "(60660, 8130)\n",
      "(60660, 8313)\n",
      "(60660, 8490)\n",
      "(60660, 8534)\n",
      "(60660, 8621)\n",
      "(60660, 8930)\n",
      "(60660, 9378)\n",
      "(60660, 9930)\n",
      "(60660, 11156)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'OmicsExpressionProteinCodingGenesTPMLogp1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Map ensembleID to gene names so I can align the datasets\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m depmap_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOmicsExpressionProteinCodingGenesTPMLogp1.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m depmap_geneNames \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgencode.v36.annotation.gtf.gene.probemap\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m id2name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(depmap_geneNames\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m], depmap_geneNames\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[0;32m/research/labs/microbiome/chia/m214779/miniconda3/envs/drp/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/research/labs/microbiome/chia/m214779/miniconda3/envs/drp/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/research/labs/microbiome/chia/m214779/miniconda3/envs/drp/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/research/labs/microbiome/chia/m214779/miniconda3/envs/drp/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/research/labs/microbiome/chia/m214779/miniconda3/envs/drp/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'OmicsExpressionProteinCodingGenesTPMLogp1.csv'"
     ]
    }
   ],
   "source": [
    "for i,f in enumerate(os.listdir('tcga_expression_data')):\n",
    "    if i == 0:\n",
    "        df = pd.read_csv(f'tcga_expression_data/{f}', sep='\\t', header=0, index_col=0)\n",
    "    else:\n",
    "        temp = pd.read_csv(f'tcga_expression_data/{f}', sep='\\t', header=0, index_col=0)\n",
    "        df = df.join(temp)\n",
    "    print(df.shape)\n",
    "\n",
    "\n",
    "# Map ensembleID to gene names so I can align the datasets\n",
    "depmap_df = pd.read_csv('OmicsExpressionProteinCodingGenesTPMLogp1.csv', index_col=0)\n",
    "depmap_geneNames = pd.read_csv('gencode.v36.annotation.gtf.gene.probemap', sep='\\t', header=0)\n",
    "\n",
    "id2name = dict(zip(depmap_geneNames.iloc[:,0], depmap_geneNames.iloc[:,1]))\n",
    "tcga_names = [id2name[x] for x in list(df.index)]\n",
    "df.index = tcga_names\n",
    "\n",
    "# Remove weird parenthesis things from end of gene names in depmap\n",
    "depmap_df = depmap_df.T\n",
    "replace_index = [re.sub(r'\\([^)]*\\)', '', x) for x in list(depmap_df.index)]\n",
    "replace_index = [x.strip() for x in replace_index]\n",
    "print(replace_index)\n",
    "depmap_df.index = replace_index\n",
    "\n",
    "# Drop repeat index in both\n",
    "depmap_df = depmap_df[~depmap_df.index.duplicated(keep='first')]\n",
    "df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "# Filter by inner join index, but don't do the actual inner join so we can keep df separate\n",
    "temp = df.loc[list(set(depmap_df.join(df, how='inner').index)),:]\n",
    "temp = temp.T\n",
    "print(temp.shape)\n",
    "\n",
    "temp = depmap_df.loc[(depmap_df.join(df, how='inner').index),:]\n",
    "temp = temp.T\n",
    "print(temp.shape)\n",
    "temp.to_csv('input_files/depmap_expression_pt_filtered.txt', sep='\\t', header=True, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
