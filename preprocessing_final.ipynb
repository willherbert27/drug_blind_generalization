{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4052191f",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d18160",
   "metadata": {},
   "source": [
    "The bulk of this paper is dependent upon multiple different manipulations of cancer drug response data. This notebook is designed to generate all required files for experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34dd0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import pubchempy as pcp\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be63f49",
   "metadata": {},
   "source": [
    "## Required files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c28ca",
   "metadata": {},
   "source": [
    "There are 5 required data files before preprocessing. Please download both DepMap files manually from the hyperlinks. The cell below will download everything else.\n",
    "\n",
    "(1) CTRPv2 response data\n",
    "\n",
    "(2) GDSC response data \n",
    "\n",
    "(3) gCSI response data \n",
    "\n",
    "(4) [DepMap cell line gene expression](https://depmap.org/portal/data_page/?tab=allData&releasename=DepMap%20Public%2024Q4&filename=OmicsExpressionProteinCodingGenesTPMLogp1.csv)\n",
    "\n",
    "(5) [DepMap manifest](https://depmap.org/portal/data_page/?tab=allData&releasename=DepMap%20Public%2024Q4&filename=Model.csv) \n",
    "\n",
    "(6) TCGA gene expression - Obtained individually from [UCSC Xena Browser](https://xenabrowser.net/datapages/?cohort=GDC%20TCGA%20Acute%20Myeloid%20Leukemia%20(LAML)&removeHub=https%3A%2F%2Fxena.treehouse.gi.ucsc.edu%3A443) (GDC hub, STAR TPM). Link provided is Google Drive maintained with all patient expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b015cdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-28 17:11:15--  https://ctd2-data.nci.nih.gov/Public/Broad/CTRPv2.0_2015_ctd2_ExpandedDataset/CTRPv2.0_2015_ctd2_ExpandedDataset.zip\n",
      "Resolving ctd2-data.nci.nih.gov (ctd2-data.nci.nih.gov)... 129.43.254.216, 2607:f220:41d:21c1::812b:fed8\n",
      "Connecting to ctd2-data.nci.nih.gov (ctd2-data.nci.nih.gov)|129.43.254.216|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 342737645 (327M) [application/zip]\n",
      "Saving to: ‘CTRPv2.0_2015_ctd2_ExpandedDataset.zip’\n",
      "\n",
      "CTRPv2.0_2015_ctd2_ 100%[===================>] 326.86M  2.75MB/s    in 2m 0s   \n",
      "\n",
      "2025-05-28 17:13:15 (2.72 MB/s) - ‘CTRPv2.0_2015_ctd2_ExpandedDataset.zip’ saved [342737645/342737645]\n",
      "\n",
      "Archive:  CTRPv2.0_2015_ctd2_ExpandedDataset.zip\n",
      "  inflating: CTRPv2.0._COLUMNS.xlsx  \n",
      "  inflating: CTRPv2.0._INFORMER_SET.xlsx  \n",
      "  inflating: CTRPv2.0._README.docx   \n",
      "  inflating: MANIFEST.txt            \n",
      "  inflating: v20._COLUMNS.txt        \n",
      "  inflating: v20.data.curves_post_qc.txt  \n",
      "  inflating: v20.data.per_cpd_avg.txt  \n",
      "  inflating: v20.data.per_cpd_post_qc.txt  \n",
      "  inflating: v20.data.per_cpd_pre_qc.txt  \n",
      "  inflating: v20.data.per_cpd_well.txt  \n",
      "  inflating: v20.meta.media_comp.txt  \n",
      "  inflating: v20.meta.per_assay_plate.txt  \n",
      "  inflating: v20.meta.per_cell_line.txt  \n",
      "  inflating: v20.meta.per_compound.txt  \n",
      "  inflating: v20.meta.per_experiment.txt  \n",
      "  inflating: v20._README.txt         \n",
      "--2025-05-28 17:13:27--  https://cog.sanger.ac.uk/cancerrxgene/GDSC_release8.5/GDSC2_fitted_dose_response_27Oct23.xlsx\n",
      "Resolving cog.sanger.ac.uk (cog.sanger.ac.uk)... 193.62.203.62, 193.62.203.63, 193.62.203.61\n",
      "Connecting to cog.sanger.ac.uk (cog.sanger.ac.uk)|193.62.203.62|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 21330376 (20M) [application/vnd.openxmlformats-officedocument.spreadsheetml.sheet]\n",
      "Saving to: ‘GDSC2_fitted_dose_response_27Oct23.xlsx’\n",
      "\n",
      "GDSC2_fitted_dose_r 100%[===================>]  20.34M  5.29MB/s    in 5.1s    \n",
      "\n",
      "2025-05-28 17:13:33 (3.98 MB/s) - ‘GDSC2_fitted_dose_response_27Oct23.xlsx’ saved [21330376/21330376]\n",
      "\n",
      "--2025-05-28 17:13:33--  http://research-pub.gene.com/gCSI_GRvalues2019/gCSI_GRdata_v1.3.tsv.tar.gz\n",
      "Resolving research-pub.gene.com (research-pub.gene.com)... 72.34.128.38\n",
      "Connecting to research-pub.gene.com (research-pub.gene.com)|72.34.128.38|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6476758 (6.2M) [application/octet-stream]\n",
      "Saving to: ‘gCSI_GRdata_v1.3.tsv.tar.gz’\n",
      "\n",
      "gCSI_GRdata_v1.3.ts 100%[===================>]   6.18M  1.11MB/s    in 5.8s    \n",
      "\n",
      "2025-05-28 17:13:39 (1.06 MB/s) - ‘gCSI_GRdata_v1.3.tsv.tar.gz’ saved [6476758/6476758]\n",
      "\n",
      "OUTPUT/gCSI_GRvalues_v1.3.tsv\n",
      "OUTPUT/gCSI_GRmetrics_v1.3.tsv\n",
      "/research/labs/microbiome/chia/m214779/miniconda3/envs/drp/lib/python3.11/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1wdGLJVAVCtK7Az4qtjsTvw-RJ-PLiIue\n",
      "From (redirected): https://drive.google.com/uc?id=1wdGLJVAVCtK7Az4qtjsTvw-RJ-PLiIue&confirm=t&uuid=0b552dde-860e-4bdb-ad88-0726b4c0702b\n",
      "To: /research/labs/microbiome/chia/m214779/drug_blind_generalization/tcga_expression_data.zip\n",
      "100%|██████████████████████████████████████| 3.15G/3.15G [02:20<00:00, 22.4MB/s]\n",
      "unzip:  cannot find or open tcga_patient_expression.zip, tcga_patient_expression.zip.zip or tcga_patient_expression.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget https://ctd2-data.nci.nih.gov/Public/Broad/CTRPv2.0_2015_ctd2_ExpandedDataset/CTRPv2.0_2015_ctd2_ExpandedDataset.zip #CTRPv2\n",
    "!unzip CTRPv2.0_2015_ctd2_ExpandedDataset.zip\n",
    "!wget https://cog.sanger.ac.uk/cancerrxgene/GDSC_release8.5/GDSC2_fitted_dose_response_27Oct23.xlsx #GDSC2\n",
    "!wget http://research-pub.gene.com/gCSI_GRvalues2019/gCSI_GRdata_v1.3.tsv.tar.gz #gCSI\n",
    "!tar -xzvf gCSI_GRdata_v1.3.tsv.tar.gz\n",
    "!gdown --id 1wdGLJVAVCtK7Az4qtjsTvw-RJ-PLiIue #TCGA patient expression, please contact authors if this fails. Alternatively, download files manually from XENA browser above.\n",
    "!unzip tcga_expression_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa7d78",
   "metadata": {},
   "source": [
    "## Generate response files for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0732fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('input_files'):\n",
    "    os.mkdir('input_files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd2498",
   "metadata": {},
   "source": [
    "We generate response files where each line is a tab-separated list containing (cell line, drug, response)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c99a06",
   "metadata": {},
   "source": [
    "### CTRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f78bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('input_files/ctrp'):\n",
    "    os.mkdir('input_files/ctrp')\n",
    "cellLine_meta_df = pd.read_csv('v20.meta.per_cell_line.txt', sep='\\t')\n",
    "experiment_meta_df = pd.read_csv('v20.meta.per_experiment.txt', sep='\\t')\n",
    "drug_meta_df = pd.read_csv('v20.meta.per_compound.txt', sep='\\t')\n",
    "experiment_results = pd.read_csv('v20.data.curves_post_qc.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39f43dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map ID values to drugs and cell lines, this is how they are represented in experiments.\n",
    "id2cell = dict(zip(cellLine_meta_df.master_ccl_id, cellLine_meta_df.ccl_name))\n",
    "id2drug = dict(zip(drug_meta_df.master_cpd_id, drug_meta_df.cpd_name))\n",
    "\n",
    "# Get dict where key = experiment ID, val = cell line ID\n",
    "exp2cell = dict(zip(experiment_meta_df.experiment_id, experiment_meta_df.master_ccl_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b764572",
   "metadata": {},
   "source": [
    "#### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a14715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict that is the final precursor for our tuple output file\n",
    "auc_dict = dict(zip(zip(experiment_results.experiment_id, experiment_results.master_cpd_id), experiment_results.area_under_curve))\n",
    "auc_named_dict = {}\n",
    "for k,v in auc_dict.items():\n",
    "    auc_named_dict[(id2cell[exp2cell[k[0]]], id2drug[k[1]])] = v\n",
    "\n",
    "# Prevent from appending to file if it's already there\n",
    "if os.path.exists('input_files/ctrp/ctrp_auc.txt'):\n",
    "    os.remove('input_files/ctrp/ctrp_auc.txt')\n",
    "\n",
    "with open('input_files/ctrp/ctrp_auc.txt', 'a') as f:\n",
    "    for k,v in auc_named_dict.items():\n",
    "        f.write(f'{k[0]}\\t{k[1]}\\t{v}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa841e",
   "metadata": {},
   "source": [
    "#### EC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f622b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec50_dict = dict(zip(zip(experiment_results.experiment_id, experiment_results.master_cpd_id), experiment_results.apparent_ec50_umol))\n",
    "ec50_named_dict = {}\n",
    "for k,v in ec50_dict.items():\n",
    "    if v >= -20 and v <= 20: # CTRP reports values in apparent ec50 uM, some of these values are extreme and disrupt training (exploding loss). Filter for realistic values. (20 + -6 = 10^14 M concentration...)\n",
    "        ec50_named_dict[(id2cell[exp2cell[k[0]]], id2drug[k[1]])] = v\n",
    "\n",
    "# Prevent from appending to file if it's already there\n",
    "if os.path.exists('input_files/ctrp/ctrp_ec50.txt'):\n",
    "    os.remove('input_files/ctrp/ctrp_ec50.txt')\n",
    "\n",
    "with open('input_files/ctrp/ctrp_ec50.txt', 'a') as f:\n",
    "    for k,v in ec50_named_dict.items():\n",
    "        f.write(f'{k[0]}\\t{k[1]}\\t{v}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a46024",
   "metadata": {},
   "source": [
    "### GDSC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c51df",
   "metadata": {},
   "source": [
    "GDSC is much easier, it's all in one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf01dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('input_files/gdsc'):\n",
    "    os.mkdir('input_files/gdsc')\n",
    "gdsc_response_df = pd.read_excel('GDSC2_fitted_dose_response_27Oct23.xlsx')\n",
    "gdsc_response_df[['CELL_LINE_NAME', 'DRUG_NAME', 'LN_IC50']].to_csv('input_files/gdsc/gdsc_ec50.txt', sep='\\t', header=False, index=False)\n",
    "gdsc_response_df[['CELL_LINE_NAME', 'DRUG_NAME', 'AUC']].to_csv('input_files/gdsc/gdsc_auc.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563fcb8b",
   "metadata": {},
   "source": [
    "### gCSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecc65c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "gCSI_df = pd.read_csv('/research/labs/microbiome/chia/m214779/gCSI/gCSI_GRmetrics_v1.3.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bba5fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('input_files/gcsi'):\n",
    "    os.mkdir('input_files/gcsi')\n",
    "\n",
    "# gCSI data has missing values, have to filter for them for each metric as we go\n",
    "\n",
    "temp = gCSI_df[gCSI_df['GR50'].notna()]\n",
    "temp = temp[temp['GR50'] < np.inf]\n",
    "temp = temp[temp['GR50'] > -np.inf]\n",
    "temp['GR50'] = temp['GR50'].apply(np.log) # log transform GR50 for prediction\n",
    "temp[['Norm_CellLineName', 'Norm_DrugName', 'GR50']].to_csv('input_files/gcsi/gcsi_gr50.txt', sep='\\t', header=False, index=False)\n",
    "\n",
    "temp = gCSI_df[gCSI_df['GR_AOC'].notna()]\n",
    "temp = temp[temp['GR_AOC'] < np.inf]\n",
    "temp = temp[temp['GR_AOC'] > -np.inf]\n",
    "temp[['Norm_CellLineName', 'Norm_DrugName', 'GR_AOC']].to_csv('input_files/gcsi/gcsi_aoc.txt', sep='\\t', header=False, index=False)\n",
    "\n",
    "temp = gCSI_df[gCSI_df['GRmax'].notna()]\n",
    "temp = temp[temp['GRmax'] < np.inf]\n",
    "temp = temp[temp['GRmax'] > -np.inf]\n",
    "temp[['Norm_CellLineName', 'Norm_DrugName', 'GRmax']].to_csv('input_files/gcsi/gcsi_grmax.txt', sep='\\t', header=False, index=False)\n",
    "\n",
    "temp = gCSI_df[gCSI_df['Emax'].notna()]\n",
    "temp = temp[temp['Emax'] < np.inf]\n",
    "temp = temp[temp['Emax'] > -np.inf]\n",
    "temp[['Norm_CellLineName', 'Norm_DrugName', 'Emax']].to_csv('input_files/gcsi/gcsi_emax.txt', sep='\\t', header=False, index=False)\n",
    "\n",
    "temp = gCSI_df[gCSI_df['GRinf'].notna()]\n",
    "temp = temp[temp['GRinf'] < np.inf]\n",
    "temp = temp[temp['GRinf'] > -np.inf]\n",
    "temp[['Norm_CellLineName', 'Norm_DrugName', 'GRinf']].to_csv('input_files/gcsi/gcsi_grinf.txt', sep='\\t', header=False, index=False)\n",
    "\n",
    "temp = gCSI_df[gCSI_df['GR_05uM_fit'].notna()]\n",
    "temp = temp[temp['GR_05uM_fit'] < np.inf]\n",
    "temp = temp[temp['GR_05uM_fit'] > -np.inf]\n",
    "temp[['Norm_CellLineName', 'Norm_DrugName', 'GR_05uM_fit']].to_csv('input_files/gcsi/gcsi_gr_05um_fit.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b2b03",
   "metadata": {},
   "source": [
    "### Filtering datasets for cell lines with expression values in DepMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b633b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_files/gdsc/gdsc_ec50.txt\n",
      "(242036, 3)\n",
      "(234020, 3)\n",
      "input_files/gdsc/gdsc_auc.txt\n",
      "(242036, 3)\n",
      "(234020, 3)\n",
      "input_files/gcsi/gcsi_grmax.txt\n",
      "(16304, 3)\n",
      "(15835, 3)\n",
      "input_files/gcsi/gcsi_gr50.txt\n",
      "(10765, 3)\n",
      "(10446, 3)\n",
      "input_files/gcsi/gcsi_grinf.txt\n",
      "(16304, 3)\n",
      "(15835, 3)\n",
      "input_files/gcsi/gcsi_gr_05um_fit.txt\n",
      "(16304, 3)\n",
      "(15835, 3)\n",
      "input_files/gcsi/gcsi_emax.txt\n",
      "(16688, 3)\n",
      "(16203, 3)\n",
      "input_files/gcsi/gcsi_aoc.txt\n",
      "(16304, 3)\n",
      "(15835, 3)\n",
      "input_files/ctrp/ctrp_auc.txt\n",
      "(387130, 3)\n",
      "(365321, 3)\n",
      "input_files/ctrp/ctrp_ec50.txt\n",
      "(282825, 3)\n",
      "(266709, 3)\n"
     ]
    }
   ],
   "source": [
    "index_df = pd.read_csv('Model.csv')\n",
    "strip_dict = pd.Series(index_df['ModelID'].values,index=index_df['StrippedCellLineName']).to_dict()\n",
    "\n",
    "# Get all of our input response files\n",
    "response_files = []\n",
    "for dirpath, dirnames, filenames in os.walk('input_files'):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(dirpath, filename)\n",
    "        response_files.append(file_path)\n",
    "\n",
    "for response_file in response_files:\n",
    "    print(response_file)\n",
    "    curr_df = pd.read_csv(response_file, sep='\\t', header=None, index_col=None)\n",
    "    print(curr_df.shape)\n",
    "    curr_df.iloc[:,0] = curr_df.iloc[:,0].str.replace('-', '')\n",
    "    curr_df.iloc[:,0] = curr_df.iloc[:,0].str.upper()\n",
    "    curr_df.iloc[:,0] = curr_df.iloc[:,0].map(strip_dict)\n",
    "    curr_df = curr_df[curr_df.iloc[:,0].notna()]\n",
    "    print(curr_df.shape) # print change in df shape for each input file\n",
    "    root, dataset, metric = response_file.replace('.txt', '').split('/')\n",
    "    curr_df.to_csv(f'{root}/{dataset}/{metric}'+ '_expfilt.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8dcc8f",
   "metadata": {},
   "source": [
    "### Filter datasets by morgan fingerprint files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68443241",
   "metadata": {},
   "source": [
    "We need to ensure that our datasets only contain drugs for which we are able to obtain fingerprints. If you would like to generate morgan fingerprint files manually, a function is included below to do so. Otherwise, there is an option to download the pre-generated fingerprint files from Google Drive.\n",
    "\n",
    "Synonym file can be downloaded from [GDSC site](https://www.cancerrxgene.org/downloads/bulk_download) under \"All compounds screened\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47c09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMorganFingerprint(response_file, synonym_file, output_location):\n",
    "    df = pd.read_csv(response_file, sep='\\t', header=None)\n",
    "    drug_list = set(list(df.iloc[:,1]))\n",
    "\n",
    "    synonym_df = pd.read_csv(synonym_file)\n",
    "    drug_name_dict = dict(zip(synonym_df.DRUG_NAME, synonym_df.SYNONYMS))\n",
    "\n",
    "    for key,value in drug_name_dict.items():\n",
    "        value = str(value)\n",
    "        drug_name_dict[key] = value.split(', ')\n",
    "\n",
    "    smile_dict = {}\n",
    "    for item in drug_list:\n",
    "        if item == 'OligomycinA':\n",
    "            item = 'Oligomycin A'\n",
    "        ids = pcp.get_cids(item, 'name', list_return='flat')\n",
    "        if len(ids) == 0:\n",
    "            print('No compound found for {}, searching synonyms'.format(item))\n",
    "            curr_synonyms = drug_name_dict[item]\n",
    "            for synonym in curr_synonyms:\n",
    "                if synonym == 'nan':\n",
    "                    continue\n",
    "                ids = pcp.get_cids(synonym, 'name', list_return='flat')\n",
    "                if len(ids) == 0:\n",
    "                    print('No compound found for {}, synonym {}'.format(item, synonym))\n",
    "                if len(ids) == 1:\n",
    "                    print(f'Match found for synonym {synonym}!')\n",
    "                    c = pcp.Compound.from_cid(ids[0])\n",
    "                    smile_dict[item] = c.canonical_smiles\n",
    "                if len(ids) > 1:\n",
    "                    print('More than one ID found for {}, synonym {}. Using best match.'.format(item, synonym))\n",
    "                    c = pcp.Compound.from_cid(ids[0])\n",
    "                    smile_dict[item] = c.canonical_smiles\n",
    "        if len(ids) == 1:\n",
    "            c = pcp.Compound.from_cid(ids[0])\n",
    "            smile_dict[item] = c.canonical_smiles\n",
    "        if len(ids) > 1:\n",
    "            print('More than one ID found for {}. Using best match.'.format(item))\n",
    "            c = pcp.Compound.from_cid(ids[0])\n",
    "            smile_dict[item] = c.canonical_smiles\n",
    "\n",
    "    print(smile_dict)\n",
    "\n",
    "    fpgen = AllChem.GetMorganGenerator(radius=2)\n",
    "    fp_dict = {}\n",
    "\n",
    "    for drug,smile_string in smile_dict.items():\n",
    "        m1 = Chem.MolFromSmiles(smile_string)\n",
    "        curr_fp = fpgen.GetFingerprint(m1)\n",
    "        fp_dict[drug] = list(curr_fp)\n",
    "\n",
    "    print(fp_dict)\n",
    "    fp_df = pd.DataFrame.from_dict(fp_dict)\n",
    "    fp_df = pd.DataFrame.transpose(fp_df)\n",
    "    fp_df.to_csv(output_location, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c8deaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/research/labs/microbiome/chia/m214779/miniconda3/envs/drp/lib/python3.11/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1XBMuz3YeHSRh1mtFdy3Rb-4mqMoF7FMQ\n",
      "To: /research/labs/microbiome/chia/m214779/drug_blind_generalization/fingerprints.zip\n",
      "100%|█████████████████████████████████████████| 108k/108k [00:00<00:00, 180MB/s]\n",
      "Archive:  fingerprints.zip\n",
      "  inflating: fingerprints/ctrp_fingerprints.txt  \n",
      "  inflating: fingerprints/gcsi_fingerprints.txt  \n",
      "  inflating: fingerprints/gdsc_fingerprints.txt  \n"
     ]
    }
   ],
   "source": [
    "# Download fingerprint files\n",
    "!gdown --id 1XBMuz3YeHSRh1mtFdy3Rb-4mqMoF7FMQ\n",
    "!unzip fingerprints.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f133d5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_files/gdsc/gdsc_ec50_expfilt.txt\n",
      "(234020, 3)\n",
      "(194491, 3)\n",
      "input_files/gdsc/gdsc_auc_expfilt.txt\n",
      "(234020, 3)\n",
      "(194491, 3)\n",
      "input_files/gcsi/gcsi_emax_expfilt.txt\n",
      "(16203, 3)\n",
      "(11470, 3)\n",
      "input_files/gcsi/gcsi_gr_05um_fit_expfilt.txt\n",
      "(15835, 3)\n",
      "(11198, 3)\n",
      "input_files/gcsi/gcsi_grmax_expfilt.txt\n",
      "(15835, 3)\n",
      "(11198, 3)\n",
      "input_files/gcsi/gcsi_grinf_expfilt.txt\n",
      "(15835, 3)\n",
      "(11198, 3)\n",
      "input_files/gcsi/gcsi_aoc_expfilt.txt\n",
      "(15835, 3)\n",
      "(11198, 3)\n",
      "input_files/gcsi/gcsi_gr50_expfilt.txt\n",
      "(10446, 3)\n",
      "(7635, 3)\n",
      "input_files/ctrp/ctrp_auc_expfilt.txt\n",
      "(365321, 3)\n",
      "(365321, 3)\n",
      "input_files/ctrp/ctrp_ec50_expfilt.txt\n",
      "(266709, 3)\n",
      "(266709, 3)\n"
     ]
    }
   ],
   "source": [
    "response_files = []\n",
    "for dirpath, dirnames, filenames in os.walk('input_files'):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('expfilt.txt'):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            response_files.append(file_path)\n",
    "\n",
    "for response_file in response_files:\n",
    "    print(response_file)\n",
    "    root, dataset, metric = response_file.replace('_expfilt.txt', '').split('/')\n",
    "    response_df = pd.read_csv(response_file, sep='\\t', header=None, index_col=None)\n",
    "    print(response_df.shape)\n",
    "    fp_df = pd.read_csv(f'fingerprints/{dataset}_fingerprints.txt', sep='\\t', index_col=0)\n",
    "    filt_drugs = list(fp_df.index)\n",
    "    response_df = response_df[response_df.iloc[:,1].isin(filt_drugs)]\n",
    "    print(response_df.shape)\n",
    "    response_df.to_csv(f'{root}/{dataset}/{metric}'+ '_expfilt_fpfilt.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c858f6",
   "metadata": {},
   "source": [
    "### Filter expression data to match with TCGA expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8709b1bc",
   "metadata": {},
   "source": [
    "Original planned utility of model was with patient few-shot example, so expression has been filtered to match up with TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d28c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,f in enumerate(os.listdir('tcga_expression_data')):\n",
    "    if i == 0:\n",
    "        df = pd.read_csv(f'tcga_expression_data/{f}', sep='\\t', header=0, index_col=0)\n",
    "    else:\n",
    "        temp = pd.read_csv(f'tcga_expression_data/{f}', sep='\\t', header=0, index_col=0)\n",
    "        df = df.join(temp)\n",
    "\n",
    "# Map ensembleID to gene names so I can align the datasets\n",
    "depmap_df = pd.read_csv('OmicsExpressionProteinCodingGenesTPMLogp1.csv', index_col=0)\n",
    "depmap_geneNames = pd.read_csv('gencode.v36.annotation.gtf.gene.probemap', sep='\\t', header=0)\n",
    "\n",
    "id2name = dict(zip(depmap_geneNames.iloc[:,0], depmap_geneNames.iloc[:,1]))\n",
    "tcga_names = [id2name[x] for x in list(df.index)]\n",
    "df.index = tcga_names\n",
    "\n",
    "# Remove weird parenthesis things from end of gene names in depmap\n",
    "depmap_df = depmap_df.T\n",
    "replace_index = [re.sub(r'\\([^)]*\\)', '', x) for x in list(depmap_df.index)]\n",
    "replace_index = [x.strip() for x in replace_index]\n",
    "depmap_df.index = replace_index\n",
    "\n",
    "# Drop repeat index in both\n",
    "depmap_df = depmap_df[~depmap_df.index.duplicated(keep='first')]\n",
    "df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "# Filter by inner join index, but don't do the actual inner join so we can keep df separate\n",
    "temp = df.loc[list(set(depmap_df.join(df, how='inner').index)),:]\n",
    "temp = temp.T\n",
    "print(temp.shape)\n",
    "\n",
    "temp = depmap_df.loc[(depmap_df.join(df, how='inner').index),:]\n",
    "temp = temp.T\n",
    "print(temp.shape)\n",
    "temp.to_csv('input_files/depmap_expression_pt_filtered.txt', sep='\\t', header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d134525",
   "metadata": {},
   "source": [
    "We have our three required types of input files for the model:\n",
    "\n",
    "(1) Response data, in input_files/\n",
    "\n",
    "(2) Morgan fingerprint drug representations, in fingerprints/\n",
    "\n",
    "(3) Expression mapping for cell lines, in input_files/\n",
    "\n",
    "Now, we can clean up intermediate files. Retain GDSC files for future experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd6169",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f v20*\n",
    "!rm -f CTRP*\n",
    "!rm -f *.zip\n",
    "!rm -f gCSI*\n",
    "!rm -f MANIFEST.txt\n",
    "!rm -r -f OUTPUT/\n",
    "!rm -r -f tcga_expression_data/\n",
    "!rm -f Model.csv\n",
    "!rm -f OmicsExpressionProteinCodingGenesTPMLogp1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126805fe",
   "metadata": {},
   "source": [
    "## Cancer type dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6badfd3f",
   "metadata": {},
   "source": [
    "I wanted to track performance by specific cancer types of cell lines in downstream analyses, so a required input to my train method is a dictionary mapping cell lines to cancer type. This info is available in Model.csv. These are actually optional to include, train.py handles no cancer type dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e57bf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AUTONOMIC_GANGLIA', 'COLON', 'VULVA', 'STOMACH', 'MPNST', 'BRAIN_BONE', 'THYROID', 'LARGE_INTESTINE', 'SKIN', 'KIDNEY', 'ADRENAL_CORTEX', 'SKIN_FV3_RESISTANT', 'SKIN_CJ2_RESISTANT', 'MELANOMA_SKIN', 'UPPER_AERODIGESTIVE_TRACT', 'SOFT_TISSUE', 'BILIARY_TRACT', 'BRAIN', 'URINARY_TRACT', 'MELANOMA_EYE', 'GASTRIC', 'OESOPHAGUS', 'ENDOMETRIUM', 'OSTEOSARCOMA', 'CENTRAL_NERVOUS_SYSTEM', 'BONE', 'PROSTATE', 'SKIN_CJ1_RESISTANT', 'BREAST', 'SALIVARY_GLAND', 'UVEA', 'TESTIS', 'HAEMATOPOIETIC_AND_LYMPHOID_TISSUE', 'EYE', 'SARCOMA', 'OVARY', 'SKIN_FV1_RESISTANT', 'CERVIX', 'SKIN_FV2_RESISTANT', 'LIVER', 'LUNG', 'NAN', 'PLEURA', 'PLACENTA', 'SKIN_CJ3_RESISTANT', 'MATCHED_NORMAL_TISSUE', 'SMALL_INTESTINE', 'PANCREAS', 'FIBROBLAST', 'PRIMARY', 'ENGINEERED'}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Model.csv')\n",
    "# the best categorization of cancer type is in the CCLE name\n",
    "cancer_types = [str(x).split('_',1) for x in list(df['CCLEName'])] \n",
    "split_cancer_type = [x[1].upper() if len(x) > 1 else x[0].upper() for x in cancer_types]\n",
    "print(set(split_cancer_type)) # list of unique cancer types for CCLE cell lines\n",
    "cancer_type_dict = dict(zip(list(df['ModelID']), split_cancer_type))\n",
    "with open('cancerType_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(cancer_type_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f3ce7c",
   "metadata": {},
   "source": [
    "## Permutation experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2596a567",
   "metadata": {},
   "source": [
    "We need to generate 3 types of files for each dataset+metric: intradrug permutation, intracell permutation, and one-hot cell line representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fce2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_files = []\n",
    "for dirpath, dirnames, filenames in os.walk('input_files'):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('fpfilt.txt'): # get filtered files only\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            response_files.append(file_path)\n",
    "\n",
    "\n",
    "for response_file in response_files:\n",
    "    root, dataset, metric = response_file.replace('_expfilt_fpfilt.txt', '').split('/')\n",
    "    df = pd.read_csv(response_file, sep='\\t', header=None)\n",
    "    \n",
    "    #Generate intradrug shuffle files\n",
    "    all_df = []\n",
    "    for unique_drug in set(list(df.iloc[:,1])):\n",
    "        temp_df = df.loc[df.iloc[:,1]==unique_drug,:]\n",
    "        temp_response = list(temp_df.iloc[:,2])\n",
    "        random.shuffle(temp_response)\n",
    "        temp_df.iloc[:,2] = temp_response\n",
    "        all_df.append(temp_df)\n",
    "\n",
    "    final_df = pd.concat(all_df)\n",
    "    final_df.to_csv(f'{root}/{dataset}/{metric}_intradrug_shuffle.txt', sep='\\t', header=None, index=None)\n",
    "\n",
    "    #Generate intracell shuffle\n",
    "    all_df = []\n",
    "    for unique_cell in set(list(df.iloc[:,0])):\n",
    "        temp_df = df.loc[df.iloc[:,0]==unique_cell,:]\n",
    "        temp_response = list(temp_df.iloc[:,2])\n",
    "        random.shuffle(temp_response)\n",
    "        temp_df.iloc[:,2] = temp_response\n",
    "        all_df.append(temp_df)\n",
    "\n",
    "    final_df = pd.concat(all_df)\n",
    "    final_df.to_csv(f'{root}/{dataset}/{metric}_intracell_shuffle.txt', sep='\\t', header=None, index=None)\n",
    "\n",
    "    # Create one-hot cell line representations - THESE ARE USED AS CELL LINE REPRESENTATION INPUT, NOT RESPONSE\n",
    "    unique_cellLines = list(set(list(df.iloc[:,0])))\n",
    "    temp_array = np.zeros((len(unique_cellLines), len(unique_cellLines)))\n",
    "    print(metric, len(unique_cellLines))\n",
    "    for i,cellLine in enumerate(unique_cellLines):\n",
    "        temp_array[i,i] = 1\n",
    "    final_df = pd.DataFrame(temp_array)\n",
    "    final_df.index = (unique_cellLines)\n",
    "    final_df.to_csv(f'{root}/{dataset}/{metric}_one_hot.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0f3bc5",
   "metadata": {},
   "source": [
    "## Dataset diversity experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307c0349",
   "metadata": {},
   "source": [
    "For these experiments, we must generate a split of the dataset where all unique drugs have at least 500 cell lines. This will remove 14 drugs. We only perform the remaining experiments in GDSC EC50. These experiments are then run using subsets.py and subsets_drug_blind.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "772845f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input_files/gdsc/gdsc_ec50_expfilt_fpfilt.txt', sep='\\t', header=None)\n",
    "# Create datasets where drugs have been tested on a minimum of 500 cell lines\n",
    "drugs = list(df.iloc[:,1])\n",
    "unique_drugs = list(set(drugs))\n",
    "drug_counts = {drug:drugs.count(drug) for drug in unique_drugs} # Create dict with drug names and # of cell lines drug is tested on\n",
    "bad_drugs = [k for k,v in drug_counts.items() if v < 500] # create list of drugs tested on less than 500 cell lines so we leave those out\n",
    "df = df[~df.iloc[:,1].isin(bad_drugs)] # filter drug response dataset by drugs w/ less than 500 cell lines\n",
    "df.to_csv('input_files/gdsc/gdsc_ec50_numCellLineSubset.txt', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01adff9",
   "metadata": {},
   "source": [
    "## Performance prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071983c",
   "metadata": {},
   "source": [
    "To perform the first performance prediction experiment, we need to generate a constant drug-blind train, test, and validation split for input to training. All models will be trained on the same val/test splits, but the composition of unique drugs in the training set will change for every model. We need to know the drugs in the training set before we make the validation and test sets though. This is the same as creating a normal drug-blind split like in subsets_drug_blind.py but input files must be created before training lots of models on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc6a91ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123 # Change this to whatever you want to generate more replicates for this experiment\n",
    "random.seed(seed)\n",
    "df = pd.read_csv('input_files/gdsc/gdsc_ec50_expfilt_fpfilt.txt', sep='\\t', header=None)\n",
    "\n",
    "# we need to presplit into training test and validation for each replicate due to drug-blind condition\n",
    "unique_drugs = list(set(df.iloc[:,1]))\n",
    "sample_idxs = random.sample(list(range(0,len(unique_drugs))), int(0.80*len(unique_drugs))) # 80% size training set\n",
    "sampled_drugs = [unique_drugs[i] for i in sample_idxs]\n",
    "val_drugs_presplit = [drug for drug in unique_drugs if drug not in sampled_drugs] # 20% validation set, before splitting into test\n",
    "val_idx = random.sample(list(range(0,len(val_drugs_presplit))), int(0.5*len(val_drugs_presplit))) \n",
    "val_drugs = [val_drugs_presplit[i] for i in val_idx]\n",
    "test_drugs = [drug for drug in val_drugs_presplit if drug not in val_drugs]\n",
    "sampled_df = df.loc[df.iloc[:,1].isin(sampled_drugs),:]\n",
    "val_df = df.loc[df.iloc[:,1].isin(val_drugs),:]\n",
    "test_df = df.loc[df.iloc[:,1].isin(test_drugs)]\n",
    "\n",
    "sampled_df.to_csv(f'input_files/gdsc/gdsc_uniqueDrug_drugBlind_train_seed{seed}.txt', sep='\\t', index=False, header=False)\n",
    "val_df.to_csv(f'input_files/gdsc/gdsc_uniqueDrug_drugBlind_val_exp_seed{seed}.txt', sep='\\t', index=False, header=False)\n",
    "test_df.to_csv(f'input_files/gdsc/gdsc_uniqueDrug_drugBlind_test_exp_seed{seed}.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bdb515",
   "metadata": {},
   "source": [
    "These output files are train/val/test inputs for subsets_uniqueDrug.py."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a24845",
   "metadata": {},
   "source": [
    "## Mechanism specific datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805472f9",
   "metadata": {},
   "source": [
    "For the mechanism specific training, we have to partition the datasets according to their pathway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "352da49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-02 16:14:59--  https://cog.sanger.ac.uk/cancerrxgene/GDSC_release8.5/screened_compounds_rel_8.5.csv\n",
      "Resolving cog.sanger.ac.uk (cog.sanger.ac.uk)... 193.62.203.61, 193.62.203.62, 193.62.203.63\n",
      "Connecting to cog.sanger.ac.uk (cog.sanger.ac.uk)|193.62.203.61|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 46414 (45K) [text/csv]\n",
      "Saving to: ‘screened_compounds_rel_8.5.csv’\n",
      "\n",
      "screened_compounds_ 100%[===================>]  45.33K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2025-06-02 16:15:01 (444 KB/s) - ‘screened_compounds_rel_8.5.csv’ saved [46414/46414]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cog.sanger.ac.uk/cancerrxgene/GDSC_release8.5/screened_compounds_rel_8.5.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa91aea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24 unique pathways in GDSC\n"
     ]
    }
   ],
   "source": [
    "gdsc_moa_df = pd.read_csv('screened_compounds_rel_8.5.csv')\n",
    "gdsc_moa_df = gdsc_moa_df.loc[~gdsc_moa_df.loc[:,'TARGET_PATHWAY'].isna(),:] # remove drugs with unknown targets\n",
    "print(f'There are {len(set(gdsc_moa_df.iloc[:,5]))} unique pathways in GDSC')\n",
    "drug_pathways_dict = {y:x for y,x in zip(gdsc_moa_df.loc[:, 'DRUG_NAME'],gdsc_moa_df.loc[:,'TARGET_PATHWAY'])}\n",
    "fp_df = pd.read_csv('fingerprints/gdsc_fingerprints.txt', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf9d6d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PI3K/MTOR signaling: ['Rapamycin', 'AZD6482', 'OSI-027', 'Temsirolimus', 'MK-2206', 'Dactolisib', 'Pictilisib', 'AZD8055', 'PF-4708671', 'AZD2014', 'AZD8186', 'Uprosertib', 'Alpelisib', 'Taselisib', 'CZC24832', 'GSK2110183B', 'Buparlisib', 'Afuresertib', 'Ipatasertib', 'GNE-317', 'AMG-319', 'LJI308', 'AT13148']\n",
      "(19862, 3)\n",
      "PI3KMTOR_signaling\n",
      "Mitosis: ['Paclitaxel', 'Tozasertib', 'Vinorelbine', 'Alisertib', 'Vinblastine', 'Docetaxel', 'ZM447439']\n",
      "(6241, 3)\n",
      "Mitosis\n",
      "EGFR signaling: ['Erlotinib', 'Lapatinib', 'Gefitinib', 'Afatinib', 'Sapitinib', 'AZD3759', 'Osimertinib']\n",
      "(6517, 3)\n",
      "EGFR_signaling\n",
      "ERK MAPK signaling: ['VX-11e', 'Refametinib', 'PLX-4720', 'PD0325901', 'SB590885', 'Selumetinib', 'Trametinib', 'Dabrafenib', 'SCH772984', 'KRAS (G12C) Inhibitor-12', 'Ulixertinib']\n",
      "(11528, 3)\n",
      "ERK_MAPK_signaling\n",
      "DNA replication: ['Gemcitabine', 'Bleomycin', 'Camptothecin', 'Cisplatin', 'Methotrexate', 'Irinotecan', 'Oxaliplatin', 'Temozolomide', 'SN-38', 'Epirubicin', 'Cyclophosphamide', 'Leflunomide', 'Topotecan', 'Teniposide', 'Mitoxantrone', 'Fludarabine', 'Nelarabine', 'LMP744', 'Pyridostatin']\n",
      "(16352, 3)\n",
      "DNA_replication\n"
     ]
    }
   ],
   "source": [
    "response_df = pd.read_csv('input_files/gdsc/gdsc_ec50_expfilt_fpfilt.txt', sep='\\t', header=None)\n",
    "\n",
    "wanted_pathways = ['PI3K/MTOR signaling','Mitosis','EGFR signaling','ERK MAPK signaling','DNA replication']\n",
    "\n",
    "for pw in wanted_pathways:\n",
    "    curr_drugs = []\n",
    "    for k,v in drug_pathways_dict.items():\n",
    "        if v == pw and k in fp_df.index:\n",
    "            curr_drugs.append(k)\n",
    "    print(f'{pw}: {curr_drugs}')\n",
    "\n",
    "    \n",
    "    temp_df = response_df[response_df.iloc[:,1].isin(curr_drugs)]\n",
    "    print(temp_df.shape)\n",
    "    print(pw.replace('/', '').replace(' ', '_'))\n",
    "    pw = pw.replace('/', '').replace(' ', '_')\n",
    "    temp_df.to_csv(f'input_files/gdsc/gdsc_{pw}_exp.txt',  sep='\\t', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
