{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d56954e",
   "metadata": {},
   "source": [
    "# Analysis of drug-to-drug information sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2b4415",
   "metadata": {},
   "source": [
    "This notebook is designed to create the heatmap figure from a set of partially drug-blind experiments. We run 1600 total models to have a training and test set for the elastic net models for each drug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa3ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "from sklearn.linear_model import  ElasticNetCV, ElasticNet\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from seaborn import clustermap\n",
    "import colorcet as cc\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_drug_oneHot(input_file, index_map, len_uniques):\n",
    "    curr_df = pd.read_csv(input_file, sep='\\t', header=None)\n",
    "    curr_uniques = list(set(curr_df.iloc[:,1]))\n",
    "    temp = np.zeros(len_uniques)\n",
    "    idx = [index_map[x] for x in curr_uniques]\n",
    "    temp[idx] = 1\n",
    "    return temp\n",
    "\n",
    "def calculate_corr_perDrug(file, index_map):\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        warnings.simplefilter(\"always\")\n",
    "        f = open(file, 'r')\n",
    "        lines = f.readlines()\n",
    "        lines = lines[1:]\n",
    "\n",
    "        drugs = [x.split('\\t')[1] for x in lines]\n",
    "        cancerTypes = [x.split('\\t')[2] for x in lines]\n",
    "        pred_responses = [x.split('\\t')[3] for x in lines]\n",
    "        true_responses = [x.split('\\t')[4].strip() for x in lines]\n",
    "        # I accidentally saved the tensor value in my experiments so we have to parse it, please don't judge me too harshly. Still works, thanks Python typecasting!\n",
    "        # TODO would be to change that in results saving\n",
    "        pred_responses_float = [float(s.split('[', 1)[1].split(']')[0]) for s in pred_responses]\n",
    "        true_responses_float = [float(s.split('[', 1)[1].split(']')[0]) for s in true_responses] \n",
    "\n",
    "        unique_drugs = list(set(drugs))\n",
    "        temp = np.zeros(len(unique_drugs))\n",
    "        for drug in unique_drugs:\n",
    "            curr_pred = [pred_responses_float[i] for i,x in enumerate(drugs) if x == drug]\n",
    "            curr_true = [true_responses_float[i] for i,x in enumerate(drugs) if x == drug]\n",
    "            if len(set(curr_pred)) == 1:\n",
    "                print(file)\n",
    "            curr_corr = pearsonr(curr_pred, curr_true)\n",
    "            \n",
    "            temp[index_map[drug]] = curr_corr.statistic\n",
    "            \n",
    "        if w:\n",
    "            print(file)\n",
    "        return temp\n",
    "    \n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    fig, ax = plt.subplots(figsize=(60,15), dpi=600)\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "    print(linkage_matrix.shape)\n",
    "    # Plot the corresponding dendrogram\n",
    "    plt.figure(figsize=(60,15), dpi=600)\n",
    "    dendrogram(linkage_matrix, ax=ax, **kwargs)\n",
    "    drug_names = [unique_map_reversed[int(x.get_text())] if '(' not in x.get_text() else x.get_text() for x in ax.get_xticklabels()]\n",
    "    print(drug_names)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels(drug_names)\n",
    "\n",
    "def calculate_linkages(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    return linkage_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a649ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index map of all unique drugs from original input file\n",
    "train_df = pd.read_csv(f'input-files/gdsc_ec50.txt', sep='\\t', header=None)\n",
    "unique_drugs = list(dict.fromkeys(train_df.iloc[:,1]))\n",
    "unique_map = {x:i for i,x in enumerate(unique_drugs)}\n",
    "len_unique = len(unique_drugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c529264",
   "metadata": {},
   "source": [
    "The below assumes that:\n",
    "\n",
    "(1) You saved all experiments with a constant prefix.\n",
    "\n",
    "(2) The seed is the last element in the file name.\n",
    "\n",
    "(3) All experiments are in the same directory for training set composition and test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ad543",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_prefix = 'your_experiment_here'\n",
    "train_dir = 'train_dir_here'\n",
    "test_dir = 'test_dir_here'\n",
    "\n",
    "train_oneHots_dict = {int(f.strip('.txt').split('_')[-1]):build_drug_oneHot(os.path.join(train_dir, f), unique_map, len_unique) \n",
    "                for f in os.listdir(train_dir) \n",
    "                if f.startswith(exp_prefix)}\n",
    "\n",
    "test_performance_byDrug = {int(f.strip('.txt').split('_')[-1]):calculate_corr_perDrug(os.path.join(test_dir,f), unique_map)\n",
    "                           for f in os.listdir(test_dir)\n",
    "                           if f.startswith(exp_prefix)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line up results by seed as the key\n",
    "total = [(train_oneHots_dict[key],test_performance_byDrug[key]) for key in test_performance_byDrug.keys()]\n",
    "X,Y = zip(*total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8bcbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate l1_ratio and alpha by 10-fold cross validation and grid search for a selected amount of drugs\n",
    "num_drugs_to_sample = 10\n",
    "drug_idx_to_test = np.random.choice(len_unique, size=num_drugs_to_sample)\n",
    "for d in drug_idx_to_test:\n",
    "    ss = ShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "    ratios = np.arange(0, 1, 0.01)\n",
    "    alphas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0]\n",
    "    model = ElasticNetCV(l1_ratio=ratios, alphas=alphas, cv=ss)\n",
    "    curr_Y = [y[int(d)] for y in Y]\n",
    "    model.fit(X,curr_Y)\n",
    "    print('alpha: %f' % model.alpha_)\n",
    "    print('l1_ratio_: %f' % model.l1_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f7c91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your alpha and l1_ratio according to above results\n",
    "\n",
    "my_alpha = 0.01\n",
    "my_l1 = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d62c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average accuracy for each drug (sorted) across all train splits\n",
    "unique_map_reversed = {v:k for k,v in unique_map.items()}\n",
    "accuracies = np.array([[y[i] for y in Y] for i in range(len_unique)]) # Get list of accuracies for each drug from list of seeded runs\n",
    "avg_accuracies = [sum(x)/len(x) for x in accuracies]\n",
    "avg_accuracies_dict = {unique_map_reversed[i]:sum(x)/len(x) for i,x in enumerate(accuracies)}\n",
    "avg_accuracies.sort(reverse=True)\n",
    "x=np.array(list(range(1, len(avg_accuracies)+1)))\n",
    "y=np.array(avg_accuracies)\n",
    "plt.figure(dpi=300)\n",
    "plt.bar(x, y, color='blue')\n",
    "plt.xlabel('drug')\n",
    "plt.ylabel('avg accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073bd9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get all coefs for ElasticNet model\n",
    "    Features: Drugs present in training set across all models [Shape: (n_models, n_drugs)]\n",
    "    Targets: Accuracies for i'th drug across all models [Shape: (n_models)]\n",
    "\n",
    "Uses 10-fold shuffle split\n",
    "'''\n",
    "ss = ShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "coefs = []\n",
    "drug_avg_scores = {}\n",
    "for j in range(len(accuracies)): # Loop over all drugs\n",
    "    curr_coefs = np.zeros(len_unique)\n",
    "    curr_Y = accuracies[j]\n",
    "    scores = []\n",
    "    for train_idx, test_idx in ss.split(X):\n",
    "        model = ElasticNet(alpha=my_alpha, l1_ratio=my_l1, max_iter=1000)\n",
    "        X_train = [X[i] for i in train_idx]\n",
    "        X_test = [X[i] for i in test_idx]\n",
    "        Y_train = [curr_Y[i] for i in train_idx]\n",
    "        Y_test = [curr_Y[i] for i in test_idx]\n",
    "        model.fit(X_train, Y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        scores.append(r2_score(Y_test,y_pred))\n",
    "        curr_coefs += model.coef_\n",
    "        # plt.scatter(y_pred, Y_test, c='blue')\n",
    "    coefs.append(curr_coefs)\n",
    "    # print(f'Average for {unique_map_reversed[j]} is {sum(scores)/len(scores)}')\n",
    "    drug_avg_scores[unique_map_reversed[j]] = sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d01b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_model = AgglomerativeClustering(n_clusters=None, distance_threshold=0, metric='euclidean', linkage='ward', compute_distances=True)\n",
    "clust_model.fit(coefs)\n",
    "linkages = calculate_linkages(clust_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d432607",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdsc_moa_df = pd.read_csv('screened_compounds_rel_8.5.csv')\n",
    "print(f'There are {len(set(gdsc_moa_df.iloc[:,5]))} unique pathways in GDSC')\n",
    "drug_pathways_dict = {y:x for y,x in zip(gdsc_moa_df.loc[:, 'DRUG_NAME'],gdsc_moa_df.loc[:,'TARGET_PATHWAY'])}\n",
    "print(drug_pathways_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e2f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on the dataset you're using, you may have to define certain drugs. Will throw error if they're not in pathways dict\n",
    "drug_pathways = pd.Series([drug_pathways_dict[drug] for drug in unique_map.keys()])\n",
    "palette = sns.color_palette(cc.glasbey, n_colors=25)\n",
    "palette = palette.as_hex()\n",
    "lut = dict(zip(drug_pathways.unique(), palette))\n",
    "row_colors = drug_pathways.map(lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69825818",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_coefs = np.abs(coefs)\n",
    "g = clustermap(coefs, col_linkage=linkages, row_linkage=linkages, cbar_pos = (0.05,0.85,0.15,.01), cbar_kws={\"orientation\": \"horizontal\"}, vmin=-1, vmax=1, cmap='icefire',dendrogram_ratio=(.2, .2),figsize=(20,20), xticklabels=1, rasterized=True, col_colors=row_colors.values)#\n",
    "drug_names = [unique_map_reversed[int(x.get_text())] if '(' not in x.get_text() else x.get_text() for x in g.ax_heatmap.get_xticklabels()] # Dendrogram is originally labeled with index of drug\n",
    "g.ax_heatmap.set_xticklabels(drug_names, verticalalignment='top')\n",
    "g.ax_heatmap.tick_params(right=False, labelright=False, bottom=False, labelbottom=False, labeltop=True, labelsize=5)\n",
    "g.ax_heatmap.tick_params(axis='x', pad=70)\n",
    "g.set_dpi = 300\n",
    "pos = g.ax_row_dendrogram.get_position()\n",
    "print(pos)\n",
    "pos.x1 = .23\n",
    "g.ax_row_dendrogram.set_position(pos)\n",
    "pos = g.ax_col_dendrogram.get_position()\n",
    "print(pos)\n",
    "pos.y1=0.95\n",
    "pos.y0=0.868\n",
    "g.ax_col_dendrogram.set_position(pos)\n",
    "cbar = g.ax_cbar\n",
    "cbar.tick_params(labelsize=15)\n",
    "plt.setp(g.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
    "markers = [mpatches.Patch(color=color, label=label) for label,color in lut.items()]\n",
    "plt.legend(handles=markers, bbox_to_anchor=(6.05,4), loc='upper left', fontsize=15, title='Pathway')\n",
    "pos = g.ax_col_colors.get_position()\n",
    "pos.y0=0.83\n",
    "pos.y1=0.865\n",
    "g.ax_col_colors.set_position(pos)\n",
    "# plt.savefig('dendro_heatmap.svg', format='svg', dpi=600,  bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
